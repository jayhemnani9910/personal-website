%-------------------------
% Data Engineer Resume - Jay Hemnani
%-------------------------

\documentclass[letterpaper,10pt]{article}

\usepackage[empty]{fullpage}
\usepackage{titlesec}
\usepackage[usenames,dvipsnames]{color}
\usepackage{enumitem}
\usepackage[hidelinks]{hyperref}
\usepackage{fancyhdr}
\usepackage[english]{babel}
\usepackage{tabularx}

% Page style
\pagestyle{fancy}
\fancyhf{}
\fancyfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}

% Tighter margins for 1-page fit
\addtolength{\oddsidemargin}{-0.6in}
\addtolength{\evensidemargin}{-0.6in}
\addtolength{\textwidth}{1.2in}
\addtolength{\topmargin}{-0.6in}
\addtolength{\textheight}{1.2in}

\urlstyle{same}
\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

% Section formatting
\titleformat{\section}{
  \vspace{-6pt}\scshape\raggedright\large\bfseries
}{}{0em}{}[\color{black}\titlerule \vspace{-6pt}]

% Custom commands
\newcommand{\resumeItem}[1]{
  \item\small{#1 \vspace{-3pt}}
}

\newcommand{\resumeSubheading}[4]{
  \vspace{-3pt}\item
    \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1} & #2 \\
      \textit{\small#3} & \textit{\small #4} \\
    \end{tabular*}\vspace{-8pt}
}

\newcommand{\resumeExpHeading}[4]{
  \vspace{-3pt}\item
    \begin{tabular*}{0.97\textwidth}[t]{l@{\extracolsep{\fill}}r}
      \textbf{#1}, \textit{#3} & #2 \\
    \end{tabular*}\vspace{-8pt}
}

\newcommand{\resumeProjectHeading}[2]{
    \item
    \begin{tabular*}{0.97\textwidth}{l@{\extracolsep{\fill}}r}
      \small#1 & #2 \\
    \end{tabular*}\vspace{-8pt}
}

\renewcommand\labelitemii{$\vcenter{\hbox{\tiny$\bullet$}}$}

\newcommand{\resumeSubHeadingListStart}{\begin{itemize}[leftmargin=0.12in, label={}]}
\newcommand{\resumeSubHeadingListEnd}{\end{itemize}}
\newcommand{\resumeItemListStart}{\begin{itemize}[leftmargin=0.15in]}
\newcommand{\resumeItemListEnd}{\end{itemize}\vspace{-6pt}}

%-------------------------------------------
% DOCUMENT START
%-------------------------------------------
\begin{document}

%----------HEADING----------
\begin{center}
    {\Huge \scshape Jay Hemnani} \\ \vspace{2pt}
    \small jayhemnani992000@gmail.com $|$ GitHub: \href{https://github.com/jayhemnani9910}{github.com/jayhemnani9910} \\
    San Jose, CA
\end{center}

%-----------EDUCATION-----------
\section{Education}
  \resumeSubHeadingListStart
    \resumeSubheading
      {Pandit Deendayal Energy University (PDEU)}{2018 -- 2022 $|$ Gandhinagar, India}
      {B.Tech in Computer Engineering $|$ GPA: 8.7/10}{}
      \resumeItemListStart
        \resumeItem{\textbf{Coursework:} Database Systems, Operating Systems, Computer Networks, Big Data Analytics.}
      \resumeItemListEnd
  \resumeSubHeadingListEnd

%-----------TECHNICAL SKILLS (FIRST for DE roles)-----------
\section{Technical Skills}
 \begin{itemize}[leftmargin=0.12in, label={}]
    \small{\item{
     \textbf{Programming:} Python, SQL, Java, Go, JavaScript \\
     \textbf{Data Engineering:} Apache Kafka, Apache Airflow, PySpark, Pandas, ETL/ELT Pipelines, Data Modeling \\
     \textbf{Databases:} PostgreSQL, MySQL, MongoDB, TimescaleDB, Redis, Data Warehousing \\
     \textbf{Cloud \& Infrastructure:} AWS (S3, EC2, Lambda, Glue), GCP (BigQuery), Docker, Kubernetes \\
     \textbf{Streaming \& Processing:} Kafka Streams, Spark Streaming, Batch Processing, Event-Driven Architecture \\
     \textbf{Tools:} Tableau, Power BI, Streamlit, Dash, Git, GitHub Actions (CI/CD)
    }}
 \end{itemize}
 \vspace{-8pt}

%-----------EXPERIENCE-----------
\section{Experience}
  \resumeSubHeadingListStart

    \resumeExpHeading
      {Data Analyst}{Summer 2025 $|$ San Jose, CA}
      {Elite Hotel Group}{}
      \resumeItemListStart
        \resumeItem{Engineered \textbf{automated ETL pipelines} using SQL and Python, reducing manual data preparation by \textbf{40\%} and improving data consistency across multi-property analytics workflows.}
        \resumeItem{Built \textbf{interactive dashboards} in Tableau/Power BI for occupancy, revenue, and KPI tracking; developed \textbf{demand forecasting models} using time-series analysis for dynamic pricing.}
      \resumeItemListEnd

    \resumeExpHeading
      {Independent Technical Consultant}{2022 -- 2024 $|$ Remote}
      {}{}
      \resumeItemListStart
        \resumeItem{Provided \textbf{data analytics and pipeline consulting} for small businesses, building reporting automation and data infrastructure solutions.}
      \resumeItemListEnd

    \resumeExpHeading
      {AI/ML Intern}{Jan -- May 2022 $|$ Gujarat, India}
      {Amnex}{}
      \resumeItemListStart
        \resumeItem{Built \textbf{fraud detection pipeline} using ensemble ML (Random Forest, XGBoost) with SMOTE for class imbalance, achieving \textbf{94\% precision} on transaction data.}
        \resumeItem{Developed \textbf{automated analytics dashboards} with statistical models for operational reporting, streamlining KPI calculations and anomaly detection workflows.}
      \resumeItemListEnd

    \resumeExpHeading
      {Software Engineering Intern}{May -- Nov 2019 $|$ Gujarat, India}
      {Cactus Creatives}{}
      \resumeItemListStart
        \resumeItem{Built \textbf{cloud-native backend services} on Azure using microservices architecture; configured \textbf{CI/CD pipelines} reducing deployment time by \textbf{60\%}.}
      \resumeItemListEnd

  \resumeSubHeadingListEnd

%-----------PROJECTS (DE-focused order)-----------
\section{Projects}
    \resumeSubHeadingListStart
      \resumeProjectHeading
          {\textbf{Stock Data Platform --- Batch + Streaming Analytics} $|$ \emph{Python, Kafka, Airflow, TimescaleDB, Dash}}{}
          \resumeItemListStart
            \resumeItem{Built \textbf{distributed streaming architecture} using Kafka topics for real-time tick ingestion, implementing idempotent writes and producer buffering for fault-tolerant data capture.}
            \resumeItem{Orchestrated \textbf{Airflow DAGs} for batch ETL pipelines handling scheduled ingests, incremental backfills, and data validation with reproducible lineage tracking.}
            \resumeItem{Designed \textbf{TimescaleDB hypertables} with star schema (FactPrices + dimensions) for time-series analytics, powering Dash dashboards with rolling indicators and intraday heatmaps.}
          \resumeItemListEnd
      \resumeProjectHeading
          {\textbf{Kayak --- Distributed Travel Metasearch} $|$ \emph{Node.js, MySQL, MongoDB, Redis, Kafka, Docker}}{}
          \resumeItemListStart
            \resumeItem{Engineered \textbf{3-tier distributed architecture} with API Gateway (JWT auth, rate limiting) routing to independent microservices for horizontal scaling.}
            \resumeItem{Achieved \textbf{sub-100ms search latency} via Redis caching layer; implemented \textbf{Kafka event streaming} for real-time inventory synchronization across services.}
            \resumeItem{Designed \textbf{hybrid storage layer} using MySQL for OLTP bookings and MongoDB for analytics/logging with optimized indexing strategies.}
          \resumeItemListEnd
      \resumeProjectHeading
          {\textbf{BarcaBrain --- Football Intelligence Platform} $|$ \emph{Python, Pandas, FAISS, Streamlit}}{}
          \resumeItemListStart
            \resumeItem{Built \textbf{data pipeline} for feature engineering on 10,000+ player records, transforming match events into dense vector embeddings for similarity search.}
            \resumeItem{Implemented \textbf{FAISS index} for k-NN retrieval achieving \textbf{$<$100ms query latency} with hybrid filters for role/league constraints.}
          \resumeItemListEnd
    \resumeSubHeadingListEnd

%-------------------------------------------
\end{document}
